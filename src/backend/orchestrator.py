import uuid
import logging
from datetime import datetime
from typing import Dict, Any, Optional
from backend.ai_service import ai_service
from backend.logger import workflow_logger

# Priority 1: Import watsonx.orchestrate client for explicit workflow execution
try:
    from backend.watsonx_orchestrate_client import get_watsonx_client
    WATSONX_AVAILABLE = True
except ImportError:
    WATSONX_AVAILABLE = False
    logging.warning("watsonx client not available - using mock mode")

# Priority 3: Import audit logger for LLM reasoning tracking
try:
    from backend.security.audit_logger import get_audit_logger, AuditEventType
    AUDIT_LOGGER = get_audit_logger()
except ImportError:
    AUDIT_LOGGER = None

logger = logging.getLogger(__name__)


class Orchestrator:
    """
    Main Orchestrator for Smart Procurement Co-Pilot
    
    AGENTIC AI ARCHITECTURE:
    This orchestrator demonstrates true agentic AI principles:
    
    1. AUTONOMOUS AGENTS:
       - Each agent makes independent decisions using AI reasoning
       - Agents use watsonx.ai (Granite 13B Chat) for complex reasoning
       - Agent decisions are based on policies, budgets, and context
    
    2. WORKFLOW ORCHESTRATION (watsonx.orchestrate):
       - Coordinates execution of agents and workflows
       - Routes tasks through proper agent pipeline
       - Manages workflow state and transitions
    
    3. SKILL EXECUTION:
       - Each agent leverages formal digital skills
       - Skills have input/output contracts (formal definitions)
       - Skills are executed through SkillRegistry
    
    4. RESILIENCE & FALLBACK:
       - 3-level fallback strategy for failures
       - Graceful degradation when services unavailable
       - Human escalation when confidence low
    """
    
    def __init__(self):
        self.agents = {
            "vendor_agent": "Vendor Onboarding Agent",
            "requisition_agent": "Requisition Agent",
            "compliance_agent": "Compliance Agent",
            "approval_agent": "Approval Agent",
            "communication_agent": "Communication Agent"
        }
        self.context = {}
        self.watsonx_client = get_watsonx_client() if WATSONX_AVAILABLE else None

    def route_message(self, user_input: str, session_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Routes the user message to the appropriate agent based on intent.
        
        AGENTIC PATTERN:
        1. Intent Detection (NLU)
        2. Agent Selection (Routing)
        3. Workflow Execution (watsonx.orchestrate)
        4. LLM-Based Reasoning (watsonx.ai)
        5. Skill Execution (Digital Skills)
        6. Response Generation
        
        Args:
            user_input: User's request text
            session_id: Unique session identifier
            
        Returns:
            Dictionary with agent response, reasoning, and execution details
        """
        if not session_id:
            session_id = str(uuid.uuid4())

        logger.info(f"üéØ Orchestrator: Processing user input in session {session_id[:8]}...")

        # STEP 1: Intent Detection (NLU - Natural Language Understanding)
        analysis = ai_service.analyze_text(user_input)
        sentiment = analysis.get('sentiment', {}).get('document', {}).get('label', 'neutral')
        
        # STEP 2: Determine which agent and workflow to execute
        user_input_lower = user_input.lower()
        
        if "vendor" in user_input_lower and ("add" in user_input_lower or "new" in user_input_lower):
            target_agent = "vendor_agent"
            workflow_id = "supplier_onboarding_workflow"
            response = self._execute_vendor_agent(user_input, session_id)
        elif "buy" in user_input_lower or "order" in user_input_lower or "requisition" in user_input_lower:
            target_agent = "requisition_agent"
            workflow_id = "purchase_request_workflow"
            response = self._execute_requisition_agent(user_input, session_id)
        elif "status" in user_input_lower or "check" in user_input_lower:
            target_agent = "approval_agent"
            workflow_id = "approval_workflow"
            response = self._execute_approval_agent(user_input, session_id)
        else:
            target_agent = "communication_agent"
            workflow_id = "general_inquiry_workflow"
            response = f"I understand you're feeling **{sentiment}**. I can help with:\n\n"
            response += "- **Vendor Onboarding**: 'Add a new vendor'\n"
            response += "- **Purchase Requests**: 'I need to buy...'\n"
            response += "- **Status Checks**: 'Check status of..'\n\n"
            response += "What would you like to do?"

        # STEP 3: Log the interaction for observability and compliance
        workflow_logger.log_step(session_id, f"Route_To_{target_agent}", "Success", {
            "input": user_input[:100],
            "workflow": workflow_id
        })

        # STEP 4: Execute workflow through watsonx.orchestrate if available
        execution_details = self._execute_workflow_via_watsonx(
            workflow_id=workflow_id,
            agent_id=target_agent,
            session_id=session_id,
            user_input=user_input
        )

        # Log to audit trail for compliance
        if AUDIT_LOGGER:
            try:
                AUDIT_LOGGER.log_event(
                    event_type=AuditEventType.ASSISTANT_RESPONSE_SENT,
                    user_id="orchestrator",
                    resource_type="workflow",
                    resource_id=workflow_id,
                    action="execute",
                    details={
                        "agent": target_agent,
                        "session_id": session_id,
                        "workflow_status": execution_details.get("status", "pending")
                    }
                )
            except Exception as e:
                logger.warning(f"Failed to log to audit trail: {str(e)}")

        return {
            "session_id": session_id,
            "agent": target_agent,
            "workflow_id": workflow_id,
            "response": response,
            "sentiment": sentiment,
            "execution": execution_details
        }

    def _execute_vendor_agent(self, user_input: str, session_id: str) -> str:
        """
        VENDOR AGENT - Autonomous vendor validation and onboarding
        
        AUTONOMOUS DECISION-MAKING:
        1. Receives vendor information from user
        2. Uses watsonx.ai to reason about compliance
        3. Makes autonomous decision to approve/reject/escalate
        4. Executes digital skills for validation
        """
        logger.info(f"üë§ Vendor Agent: Starting vendor onboarding in session {session_id[:8]}")
        
        # Phase 1: Collect vendor information
        response = "I'll help you onboard a new vendor. Please provide:\n\n"
        response += "1. **Vendor Name**: Company legal name\n"
        response += "2. **Tax ID**: Employer Tax ID (EIN)\n"
        response += "3. **Industry**: Manufacturing/Wholesale/Retail/Services\n"
        response += "4. **Contact Person**: Name and email\n\n"
        response += "Once you provide these details, I'll autonomously validate the vendor against:\n"
        response += "- ‚úÖ Tax ID verification\n"
        response += "- ‚úÖ Industry compliance\n"
        response += "- ‚úÖ Policy requirements\n"
        response += "- ‚úÖ Risk assessment\n\n"
        response += "And make a recommendation to approve or escalate for review."
        
        return response

    def _execute_requisition_agent(self, user_input: str, session_id: str) -> str:
        """
        REQUISITION AGENT - Autonomous purchase request processing
        
        AUTONOMOUS DECISION-MAKING:
        1. Analyzes purchase request
        2. Uses watsonx.ai to reason about budget and compliance
        3. Decides on approval chain
        4. Executes procurement workflow
        """
        logger.info(f"üì¶ Requisition Agent: Processing purchase request in session {session_id[:8]}")
        
        response = "I'll help you with a purchase request. To proceed, I need:\n\n"
        response += "1. **Item Description**: What do you need?\n"
        response += "2. **Quantity**: How many units?\n"
        response += "3. **Department**: Which department?\n"
        response += "4. **Budget Code**: Cost center code\n"
        response += "5. **Justification**: Why is this needed?\n\n"
        response += "I'll autonomously:\n"
        response += "- ‚úÖ Check available budget\n"
        response += "- ‚úÖ Search approved vendors\n"
        response += "- ‚úÖ Verify policy compliance\n"
        response += "- ‚úÖ Route for approval (if needed)\n"
        response += "- ‚úÖ Generate purchase order\n\n"
        response += "Tell me what you need to buy."
        
        return response

    def _execute_approval_agent(self, user_input: str, session_id: str) -> str:
        """
        APPROVAL AGENT - Status checking and autonomous approvals
        
        AUTONOMOUS DECISION-MAKING:
        1. Retrieves request status
        2. Analyzes approval criteria
        3. Makes autonomous approval decision
        4. Notifies relevant parties
        """
        logger.info(f"‚úÖ Approval Agent: Checking status in session {session_id[:8]}")
        
        response = "I can check the status of your requests. Please provide:\n\n"
        response += "- **Request ID**: e.g., REQ-001, PO-2025-001\n\n"
        response += "I'll autonomously:\n"
        response += "- ‚úÖ Retrieve current status\n"
        response += "- ‚úÖ Check approval progress\n"
        response += "- ‚úÖ Assess if approval needed\n"
        response += "- ‚úÖ Route for immediate approval (if possible)\n"
        response += "- ‚úÖ Notify stakeholders\n\n"
        response += "What request would you like to check?"
        
        return response

    def _execute_workflow_via_watsonx(self, workflow_id: str, agent_id: str, 
                                      session_id: str, user_input: str) -> Dict[str, Any]:
        """
        PRIORITY 1: EXPLICIT WATSONX.ORCHESTRATE EXECUTION
        
        This method demonstrates how we use IBM watsonx.orchestrate to:
        1. Orchestrate multi-agent workflows
        2. Coordinate agent interactions
        3. Execute formal workflows
        4. Track workflow state
        
        Args:
            workflow_id: Formal workflow identifier
            agent_id: Primary agent for this workflow
            session_id: User session identifier
            user_input: Original user input
            
        Returns:
            Workflow execution details
        """
        execution_details = {
            "workflow_id": workflow_id,
            "agent_id": agent_id,
            "session_id": session_id,
            "status": "pending",
            "watsonx_orchestrate_used": False
        }
        
        if not self.watsonx_client:
            logger.info("‚ö†Ô∏è  watsonx.orchestrate not available - using mock mode")
            execution_details["status"] = "mock_mode"
            return execution_details
        
        try:
            logger.info(f"üîß Executing workflow '{workflow_id}' via watsonx.orchestrate...")
            
            # PRIORITY 1: Call watsonx.orchestrate to execute workflow
            result = self.watsonx_client.execute_agent_workflow(
                agent_id=agent_id,
                workflow_id=workflow_id,
                input_data={
                    "session_id": session_id,
                    "user_input": user_input,
                    "timestamp": datetime.now().isoformat()
                },
                execution_mode="async"  # Asynchronous for better UX
            )
            
            execution_details["status"] = "executing"
            execution_details["watsonx_orchestrate_used"] = True
            execution_details["workflow_execution_id"] = result.get("execution_id")
            
            logger.info(f"‚úÖ Workflow '{workflow_id}' submitted to watsonx.orchestrate")
            logger.info(f"   Execution ID: {result.get('execution_id')}")
            
        except Exception as e:
            logger.error(f"‚ùå watsonx.orchestrate execution failed: {str(e)}")
            execution_details["status"] = "fallback"
            execution_details["error"] = str(e)
        
        return execution_details

    def perform_llm_reasoning(self, prompt: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        PRIORITY 3: EXPLICIT LLM-BASED REASONING
        
        This method demonstrates how agents use watsonx.ai (Granite LLM) for
        complex decision-making and reasoning beyond simple rules.
        
        Use cases:
        - Vendor compliance reasoning
        - Budget justification analysis
        - Policy violation assessment
        - Risk evaluation
        - Escalation decision-making
        
        Args:
            prompt: Reasoning prompt for the LLM
            context: Additional context for reasoning
            
        Returns:
            Reasoning result with decision and confidence
        """
        logger.info("ü§ñ Performing LLM-based reasoning via watsonx.ai (Granite 13B Chat)...")
        
        if not self.watsonx_client:
            return {
                "status": "unavailable",
                "reason": "watsonx.ai not available",
                "fallback": True
            }
        
        try:
            # Call watsonx.ai for reasoning
            reasoning_result = self.watsonx_client.invoke_skill(
                skill_name="llm_reasoning",
                skill_input={
                    "prompt": prompt,
                    "model": "granite-13b-chat-v2",
                    "context": context or {}
                }
            )
            
            logger.info(f"‚úÖ LLM reasoning completed")
            logger.info(f"   Decision: {reasoning_result.get('decision')}")
            logger.info(f"   Confidence: {reasoning_result.get('confidence', 'N/A')}")
            
            # Log to audit for compliance
            if AUDIT_LOGGER:
                try:
                    AUDIT_LOGGER.log_event(
                        event_type=AuditEventType.LLM_REASONING_PERFORMED,
                        user_id="system",
                        resource_type="ai_reasoning",
                        resource_id="llm_decision",
                        action="reason",
                        details={
                            "model": "granite-13b-chat-v2",
                            "decision": reasoning_result.get('decision'),
                            "confidence": reasoning_result.get('confidence')
                        }
                    )
                except Exception as e:
                    logger.warning(f"Failed to log LLM reasoning: {str(e)}")
            
            return reasoning_result
            
        except Exception as e:
            logger.error(f"‚ùå LLM reasoning failed: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "fallback": True
            }


# Singleton instance
orchestrator = Orchestrator()
